{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37849af0-1d78-4523-93e9-ff1f566bf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3617e7c-ac72-437e-b778-aa05e060fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_to_pixel(world_coords, camera_params, rotation_matrix):\n",
    "    # Extract camera parameters\n",
    "    camera_position = np.array(camera_params['camera_position'])\n",
    "    fov = camera_params['fov']\n",
    "    width, height = camera_params['image_resolution']\n",
    "    pixel_width = camera_params['camera_sensor_width'] / width\n",
    "    pixel_height = camera_params['camera_sensor_height'] / height\n",
    "\n",
    "    # Calculate the direction vector from the camera position to the 3D point\n",
    "    direction = (world_coords - camera_position).astype(np.float64)\n",
    "\n",
    "    # Normalize the direction vector\n",
    "    direction /= np.linalg.norm(direction)\n",
    "\n",
    "    # Apply the inverse rotation matrix to align with the camera's view\n",
    "    inv_rotation_matrix = np.linalg.inv(rotation_matrix)\n",
    "    direction = np.dot(inv_rotation_matrix, direction)\n",
    "\n",
    "    # Project the 3D point onto the 2D image plane\n",
    "    # Assuming the camera is looking along the z-axis, ignore the z-component\n",
    "    u = direction[0] * fov / 2\n",
    "    v = direction[1] * fov / 2\n",
    "\n",
    "    # Convert from camera coordinates to pixel indices\n",
    "    x_index = int((u / pixel_width) + width / 2)\n",
    "    y_index = int((v / pixel_height) + height / 2)\n",
    "\n",
    "    return x_index, y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aef1bd-8b58-4a78-879a-cee08e81f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "camera_params = {\n",
    "    'fov': 49.9,  # Field of view in degrees\n",
    "    'camera_position': [3, 3, 6],  # Camera position (x, y, z)\n",
    "    'camera_rotation': [-25, 25, 0],  # Camera rotation in degrees (pitch, roll, yaw)\n",
    "    'camera_sensor_width': 36,  # Camera sensor width in mm\n",
    "    'camera_sensor_height': 24,  # Camera sensor height in mm\n",
    "    'image_resolution': [320, 240]  # Image resolution (width, height)\n",
    "}\n",
    "\n",
    "# Calculate the camera rotation matrix\n",
    "pitch = camera_params['camera_rotation'][0] * np.pi / 180\n",
    "roll = camera_params['camera_rotation'][1] * np.pi / 180\n",
    "yaw = camera_params['camera_rotation'][2] * np.pi / 180\n",
    "\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(yaw) * np.cos(pitch), np.cos(yaw) * np.sin(pitch) * np.sin(roll) - np.sin(yaw) * np.cos(roll), np.cos(yaw) * np.sin(pitch) * np.cos(roll) + np.sin(yaw) * np.sin(roll)],\n",
    "    [np.sin(yaw) * np.cos(pitch), np.sin(yaw) * np.sin(pitch) * np.sin(roll) + np.cos(yaw) * np.cos(roll), np.sin(yaw) * np.sin(pitch) * np.cos(roll) - np.cos(yaw) * np.sin(roll)],\n",
    "    [-np.sin(pitch), np.cos(pitch) * np.sin(roll), np.cos(pitch) * np.cos(roll)]\n",
    "])\n",
    "\n",
    "# Example 3D world coordinates\n",
    "world_coords = [4, 4, 7]\n",
    "\n",
    "# Convert 3D coordinates to 2D pixel coordinates\n",
    "pixel_coords = world_to_pixel(world_coords, camera_params, rotation_matrix)\n",
    "print(\"Pixel Coordinates:\", pixel_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad6a99-cb4b-4cec-80e5-c983f4bdeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "class ColorMasker:\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.hsv_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.color_ranges = {\n",
    "            'gray': ((0, 0, 40), (30, 20, 100)),\n",
    "            'red': (((0, 100, 100), (10, 255, 255)), ((160, 100, 100), (180, 255, 255))),\n",
    "            'blue': ((110, 50, 50), (130, 255, 255)),\n",
    "            'green': ((30, 70, 60), (60, 255, 255)),\n",
    "            'brown': ((10, 100, 20), (20, 255, 200)),\n",
    "            'cyan': ((80, 90, 60), (100, 255, 255)),\n",
    "            'purple': ((130, 50, 50), (160, 255, 255)),\n",
    "            'yellow': ((25, 100, 100), (30, 255, 255))\n",
    "        }\n",
    "\n",
    "    def separate_objects(self, mask):\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        masks = []\n",
    "        for contour in contours:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                temp_mask = np.zeros_like(mask)\n",
    "                cv2.drawContours(temp_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "                masks.append(temp_mask)\n",
    "        return masks\n",
    "\n",
    "    def get_mask(self, color_code):\n",
    "        if color_code not in self.color_ranges:\n",
    "            raise ValueError(\"Invalid color code\")\n",
    "        \n",
    "        ranges = self.color_ranges[color_code]\n",
    "        if color_code == 'red':  # Red has two ranges\n",
    "            mask1 = cv2.inRange(self.hsv_image, np.array(ranges[0][0], dtype=np.uint8), np.array(ranges[0][1], dtype=np.uint8))\n",
    "            mask2 = cv2.inRange(self.hsv_image, np.array(ranges[1][0], dtype=np.uint8), np.array(ranges[1][1], dtype=np.uint8))\n",
    "            mask = cv2.bitwise_or(mask1, mask2)\n",
    "        else:\n",
    "            mask = cv2.inRange(self.hsv_image, np.array(ranges[0], dtype=np.uint8), np.array(ranges[1], dtype=np.uint8))\n",
    "        \n",
    "        return self.separate_objects(mask)\n",
    "        \n",
    "    def get_mask_arg(self, mask, predicted_centers):\n",
    "        true_indices = np.where(mask)\n",
    "        x_mask, y_mask = (int(np.mean(true_indices[0])), int(np.mean(true_indices[1])))\n",
    "        \n",
    "        # Convert predicted_centers to a numpy array if it's not already one\n",
    "        predicted_centers = np.array(predicted_centers)\n",
    "        \n",
    "        # Calculate the squared Euclidean distances to all predicted centers\n",
    "        distances = np.sum((predicted_centers - np.array([x_mask, y_mask]))**2, axis=1)\n",
    "\n",
    "        # Find the index of the closest center\n",
    "        closest_index = np.argmin(distances)\n",
    "\n",
    "        # Get the closest center coordinates\n",
    "        closest_center = predicted_centers[closest_index]\n",
    "\n",
    "        return closest_center\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de5ca2-3449-4313-9d02-f5381e8ac738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "image_1 = cv2.imread(\"dataset/train/video_00000/image_0.png\")\n",
    "imshow(cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622152c-0b8e-4ab0-bddc-86b8a0a21512",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker_1 = ColorMasker(image_1)\n",
    "color_code = 'yellow'  # Example color code\n",
    "mask_yellow = masker_1.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_yellow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de776aa7-68f1-4dbe-912a-91c91e754fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_code = 'green'  # Example color code\n",
    "mask_green = masker_1.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_green[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb2e2b-85c0-4a28-b547-88b762382d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_code = 'cyan'  # Example color code\n",
    "mask_cyan = masker_1.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_cyan[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9668e-38dd-4937-a219-9f8a1a730d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "image_2 = cv2.imread(\"dataset/train/video_00002/image_0.png\")\n",
    "imshow(cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c8438-fda7-4cf2-bcb6-39fb090d01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker_2 = ColorMasker(image_2)\n",
    "color_code = 'gray'  # Example color code\n",
    "mask_grey = masker_2.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_grey[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca0af8-387d-4c22-99b4-afc84ce52c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_code = 'purple'  # Example color code\n",
    "mask_purple = masker_2.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_purple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505eb52-384f-4316-9e71-853b793239bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "image_3 = cv2.imread(\"dataset/train/video_00003/image_0.png\", cv2.IMREAD_COLOR)\n",
    "imshow(cv2.cvtColor(image_3, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f18a0e-9b6e-4c7d-80c6-9384a3ee1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker_3 = ColorMasker(image_3)\n",
    "color_code = 'red'  # Example color code\n",
    "mask_red = masker_3.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_red[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac8922-c46a-4611-89ca-a4c4fe89fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(mask_red[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388371c7-6508-4d7a-9a9a-861e24226974",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_4 = cv2.imread(\"dataset/train/video_00004/image_0.png\", cv2.IMREAD_COLOR)\n",
    "imshow(cv2.cvtColor(image_4, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecf2ba-0d2c-4ab8-aa82-bbc54ca76f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker_4 = ColorMasker(image_4)\n",
    "color_code = 'brown'  # Example color code\n",
    "mask_brown = masker_4.get_mask(color_code)\n",
    "    \n",
    "imshow(mask_brown[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
